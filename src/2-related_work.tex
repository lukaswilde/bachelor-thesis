\thispagestyle{plain}
\chapter{Related Work}\label{sec:related_work}

In this Chapter, we first introduce different index structures that either show some sort of data partitioning or serve as a baseline to compare our algorithms. We cover traditional tree-like index structures like the B$^+$-tree, look into Radix Trees represented by the Adaptive Radix Tree and then proceed to Learned Index Structures like the Recursive Model Index and the Piecewise Geometric Index. After that, we explore two fields in which the query workload is used in data partitioning, Adaptive Hybrid Indexes, and Distributed Database Systems.

\paragraph{} 
When we look at traditional tree-like index structures, the well-known B$^+$-tree \cite{Bayer1970-rh} is the first index that comes to mind. It was designed to index a dynamically changing file, assuming that only a small part of the index can remain in the main memory. The authors acknowledged that this file could be subject to change, and as such, one would need efficient ways to not only search the index but also enable the insertion and deletion of existing keys. The nodes in a B$^+$-tree are always containing at least $k$ and at most $2k$ keys at a time, resulting in a space occupancy of at least 50\%. The keys in inner nodes act as boundaries to guide the retrieval, essentially producing disjoint ranges. Should a key fall into a specific range, the corresponding child pointer is used to get to the node of the next layer. The nodes' keys are ordered, allowing an efficient binary search. Insertion and deletion follow the same principle, except when inserting or deleting a key would result in a key count of less than $k$ or more than $2k$ inside a node. In this case, neighboring nodes need to be merged, or a node needs to be split to guarantee the invariant that each node contains between $k$ and $2k$ keys. The advantage of this index type is that the keys are kept ordered, enabling efficient predecessor/successor queries and range queries. However, B$^+$-trees have poor cache utilization since half the space is needed for the child pointers (assuming that keys and pointers have the same size). Several variants of the B$^+$-tree try to improve the caching behavior, e.g.~the Cache Sensitive B$^+$-tree (CSB$^+$-tree) \cite{Rao2000}. Their main idea is that only one child pointer is stored explicitly, and every other child can be found by adding a specific offset to that first address. This requires that child nodes are stored contiguously in memory, resulting in an overhead when nodes need to be split or merged.

The next family of indexes we look at is Radix Trees, with the Adaptive Radix Tree (ART) \cite{Leis2013} as a representative. The authors recognize that the B$^+$-tree is widely used for disk-based database systems but believe it is unsuitable for main-memory databases. This is mainly due to traditional index structures' inefficiency in CPU caching. Additionally, the problem of stalls in the modern-day CPU pipeline is caused by the CPU's inability to predict the result of comparisons easily. As comparisons are necessary to  traverse a B$^+$-tree, this causes more latency for the index. To overcome these problems, the authors introduce an improvement to Radix Trees, which uses certain parts of the keys directly to guide the search in the tree. While Radix Trees get rid of the previously mentioned CPU stalls, they often have to make a global trade-off between tree height and space efficiency. This problem is solved by introducing adaptive nodes with varying capacities to hold child pointers. Results indicate that ART can outperform other main-memory data structures, with the only competitor being a hash table in point query-only workloads. However, as these store keys in a random order, they cannot support range queries efficiently and are only useful in specific scenarios. For workloads with some range queries, hash tables are not competitive with ART anymore.

The last family of indexes we cover are Learned Index Structures, a type of index that only emerged recently. Learned index structures generally try to leverage recent progress in the field of Machine Learning to improve index performance. The Recursive Model Index (RMI) \cite{Kraska2018} introduces the concept that indexes are models that simply map keys to positions in a sorted array. The authors state that most modern index structures do not consider the data distribution and miss out on highly relevant optimizations. While most datasets don't follow simple patterns, they argue that Machine Learning (ML) approaches can be used to incorporate these patterns. One can look at finding the position of a key by traversing a B$^+$-tree as slowly reducing the error. While at the start, one would need to search in every possible location, after the first comparison with the pivot elements in a B$^+$-tree, there is only a subset of locations left (i.e.~only one child pointer to follow). The same mentality can be adapted to ML models with a slight difference: instead of being certain that a specific key is, for example, located in the left sub-tree, it would be enough for the key to be in the left sub-tree with a high probability. The authors argue that while it is hard to guarantee that a single ML model will reliably reduce the error from millions of possible locations to hundreds for the final search, it is reasonable for a model to do so from millions to tens of thousands. As these tens of thousands of locations are too large to search for the final position of the key directly, they construct a hierarchy of ML models, where each model picks the next layer's model that should be used to predict the position of the key. This hierarchy does not need to follow a balanced tree structure; each model can cover an individual number of keys. The benefit of this architecture lies in the ability to customize the models. For example, the bottom layer of nodes could only represent linear regression models (as there are many leaves and linear regression models are quite inexpensive), while higher up, one could theoretically use more complex neural network structures. In practice, however, neural networks are quite  time-consuming to evaluate, which is why mostly linear models are used. The data segmentation happens through the structure and training of the internal node's models. 

FITing-Tree \cite{Galakatos2019} tries to combine the ﬂexibility of traditional index structures with learning by indexing linear data segments. The authors argue that ML models can not only be used to speed up the lookup performance of index structures, but it is also possible to reduce the memory requirements of indexes. Recent results \cite{Zhang2016} have shown that index structures in OLTP databases can take up to 55\% of the available memory, making it all the more enticing to develop indexes that perform similarly to the state-of-the-art while reducing memory consumption. The data partitioning is done by a single pass over the sorted data. The segmentation algorithm aims to determine the data segments' bounds so that the relation between keys and positions in the sorted array can be approximated by a linear function. To give reliable performance estimates, an error parameter is used to indicate how much an estimated position is allowed to deviate from the real position. A new segment is created once a point falls outside an error cone that ensures this maximum deviation. Otherwise, the cone is adjusted by tightening its bounds. Once the segments are determined, they are indexed by a B$^+$-tree to find a key's corresponding segment.

The authors of the Piecewise Geometric Model index (PGM) \cite{Ferragina:2020pgm} tried to improve upon the ideas of FITing-Tree. While FITing-Tree's approach seemed reasonable, a disadvantage was the data segmentation. The authors note that the single-pass segmentation algorithm does not produce the optimal number of data segments, leading to more data segments, a larger tree height, and increased lookup time. By reducing the segmentation to the problem of constructing a convex hull and allowing the index to be built recursively, they could increase the lookup time and ensure provably efficient time and space bounds in the worst case. While the basic PGM index assumes a uniform query distribution across the keys, the authors also recognize that this scenario rarely happens in practice. They design the distribution-aware PGM index, which enables to search for a key $k_i$ in time $O(\log (1/p_i))$. The average lookup time then coincides with the entropy of the query distribution. The construction of the index is almost identical to the normal PGM index, except that when it is built recursively, the probabilities are used to weigh the segments based on their probability values. The segments are obtained by slightly modifying the algorithm from the normal PGM, incorporating the probabilities when constructing the convex hull. Unfortunately, while the authors of the PGM paper include an implementation of the PGM index, they did not implement the distribution-aware PGM and therefore did not include it in their experiment but rather left it as future work. 

While Learned Index Structures perform so well because they can adapt to the underlying data distribution, apart from the distribution-aware PGM, they do not consider the workload that will be executed. This is still more than the traditional index structures since they do not have any sort of segmentation built in. RMIs partition the data indirectly through their models, FITing-Tree and PGM explicitly use segmentation algorithms before building the index to determine the data that belongs in one segment. However, workload information might be beneficial to index construction, e.g.~by indicating that certain data segments are not frequently requested. My work covers whether workload information can be used to improve data segmentation and thereby yield better performance. As we do not have an implementation of the distribution-aware PGM, we use the ordinary PGM index as a comparison, as it improves FITing-Tree by using optimal segments and trumps RMI over all possible space-time trade-offs on three common datasets.

\noindent Besides the PGM index, we use a B$^+$-tree and ART as two more baselines for our comparisons such that we have representatives from the three index families we introduced.

\paragraph{}
Adaptive Hybrid Indexes \cite{Anneser2022} tackle the problem of selecting suitable encodings inside index structures to trade-off between space utilization and index performance. Compact indexes reduce the index's memory, allowing the database system to utilize that free memory to accelerate queries. This is achieved by either keeping a larger working set in memory or, when there is a memory budget for indexes, by enabling the use of more index structures that are kept in the main memory. However, they are naturally inferior to performance-optimized indexes. The decision of what encoding should be used on which part of the index is hard to make at build time. Therefore, the authors propose to make these decisions at run-time. They introduce a framework that allows for monitoring the accesses across the index nodes when queries are processed, and based on these metrics, they classify whether nodes are cold or hot. Using so-called context-sensitive heuristic functions (CSHF), the framework determines, based on the classification of hot- and coldness, the memory budget, the historical classifications, and other properties, whether a node should have a compressed or performance-optimized encoding. Especially relevant to my work is the classification as hot or cold. Once the data is split into segments and inserted into a tree-like structure, it could be beneficial to modify the index based on this classification. While the authors do this at run-time, my work focuses on analyzing the workload before building the index. While they decided to either use performance or memory-optimized encodings of nodes to represent hot or cold data, we theoretically explore other possible optimizations.

\paragraph{}
Distributed database systems are another field where the workload is used for partitioning. An example there is Schism \cite{Curino2010}. The motivation behind this approach is to improve the performance and scalability of distributed databases. Each tuple is represented as a node in a graph. Two nodes are connected if the corresponding tuples occur in the same transaction. The edges are weighted with the total amount of co-occurrences in transactions. Given some partitions $k$, the algorithm will ﬁnd a set of cuts of the edges that produces $k$ distinct partitions with roughly equal weight and minimal costs along the cut edges. The intuition behind this is that tuples that are often accessed in the same transaction should also reside in the same partition/node to optimize query processing. By minimizing the cost along the cut edges, pairs of tuples that are seldom accessed together are split into diﬀerent partitions, whereas often connected tuples stay in the same partition. While we do not look at transaction-based workloads in this work, there is a similarity in looking at workload properties to partition the data. Schism uses the frequency of co-occurrences to do this partitioning, which indicates that the frequency of query accesses could be a promising property to look at.
